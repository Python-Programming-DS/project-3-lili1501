{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 3 — MACHINE LEARNING MODELING REPORT\n",
    "## Part A: Logistic Regression\n",
    "## Part B: Random Forest (Non-Logistic Model)\n",
    "\n",
    "### 1. Introduction\n",
    "The objective of this project is to build and evaluate predictive models using a cleaned dataset. The modeling process is divided into two stages: Logistic Regression (Part A) and a more advanced non-logistic model (Random Forest, Part B).\n",
    "\n",
    "### 2. Data Cleaning & Preprocessing\n",
    "Key steps included:\n",
    "- Removing unwanted characters\n",
    "- Dropping irrelevant columns which were either empty or of ids\n",
    "- Dummy encoding categorical variables for continuous variable cols\n",
    "- Handling missing data\n",
    "- Remove highly correlated columns \n",
    "- Train/Validation/Test split\n",
    "\n",
    "### 3. Part A — Logistic Regression Model\n",
    "**Best Parameters:** {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.078}\\n\n",
    "**Validation Metrics:**\\n\n",
    "- Accuracy: 0.878\\n\n",
    "- Precision: 0.869\\n\n",
    "- Recall: 0.847\\n\n",
    "- F1: 0.858\\n\n",
    "- AUC: 0.95\\n\n",
    "*** Feature engineering (interaction + log transforms for Part A)\n",
    "**Test Metrics:**\\n\n",
    "- Accuracy: 0.873\\n\n",
    "- Precision: 0.866\\n\n",
    "- Recall: 0.833\\n\n",
    "- F1: 0.849\\n\n",
    "- AUC: 0.94\\n\n",
    "\n",
    "### Top Logistic Regression Coefficients\n",
    "- Positive: x25_LC, x14, x17, x20, x18, x9\n",
    "- Negative: x26_PT, x4, x28\n",
    "\n",
    "### 4. Part B — Random Forest Classifier\n",
    "**Best Parameters:** class_weight='balanced', max_features=0.7, min_samples_leaf=2, min_samples_split=10, n_estimators=400\n",
    "\n",
    "**Validation Metrics:**\\n\n",
    "- Accuracy: 0.964\\n\n",
    "- Precision: 0.970\\n\n",
    "- Recall: 0.946\\n\n",
    "- F1: 0.958\\n\n",
    "- AUC: 0.99\\n\n",
    "\n",
    "**Test Metrics:**\\n\n",
    "- Accuracy: 0.962\\n\n",
    "- Precision: 0.969\\n\n",
    "- Recall: 0.942\\n\n",
    "- F1: 0.955\\n\n",
    "- AUC: 0.99\\n\n",
    "\n",
    "### Top Random Forest Features\n",
    "- x14, x9, x26_PT, x28, x16, x25_LC, x5, x20, x18, x29\n",
    "\n",
    "### 5. Model Comparison\n",
    "| Metric | Logistic Regression | Random Forest |\n",
    "|--------|--------------------|---------------|\n",
    "| Test AUC | 0.94 | 0.99 |\n",
    "| Test Accuracy | 0.873 | 0.962 |\n",
    "| Test F1 | 0.849 | 0.955 |\n",
    "\n",
    "### 6. Conclusion\n",
    "Random Forest significantly outperforms Logistic Regression on all metrics, showing excellent generalization and robustness after hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
